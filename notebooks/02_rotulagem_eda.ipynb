{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d325972f",
   "metadata": {},
   "source": [
    "# üè∑Ô∏è Notebook 2: Rotulagem e An√°lise Explorat√≥ria de Dados\n",
    "\n",
    "Este notebook conduz a an√°lise explorat√≥ria dos dados coletados e demonstra o processo de rotulagem para cria√ß√£o do dataset de treinamento.\n",
    "\n",
    "## üéØ Objetivos\n",
    "- Carregar e explorar dados coletados\n",
    "- Realizar an√°lise explorat√≥ria (EDA)\n",
    "- Preparar amostra para rotulagem manual\n",
    "- Analisar qualidade e distribui√ß√£o dos dados\n",
    "- Configurar Label Studio para rotulagem\n",
    "\n",
    "## üìã Pr√©-requisitos\n",
    "- Dados coletados no Notebook 1\n",
    "- Label Studio instalado\n",
    "- Dados pr√©-processados dispon√≠veis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a22c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports para an√°lise explorat√≥ria\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "import re\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Configura√ß√£o de plots\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Adicionar src ao path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Configurar diret√≥rios\n",
    "project_root = Path(\"..\").resolve()\n",
    "data_dir = project_root / \"data\" \n",
    "raw_dir = data_dir / \"raw\"\n",
    "processed_dir = data_dir / \"processed\"\n",
    "\n",
    "print(f\"üìÅ Diret√≥rio do projeto: {project_root}\")\n",
    "print(f\"üìä Diret√≥rio de dados brutos: {raw_dir}\")\n",
    "print(f\"üîß Diret√≥rio de dados processados: {processed_dir}\")\n",
    "\n",
    "# Verificar se existem dados para analisar\n",
    "if raw_dir.exists():\n",
    "    raw_folders = [f for f in raw_dir.iterdir() if f.is_dir()]\n",
    "    print(f\"üìÇ Execu√ß√µes de coleta dispon√≠veis: {len(raw_folders)}\")\n",
    "    for folder in sorted(raw_folders)[-3:]:  # Mostrar as 3 mais recentes\n",
    "        files = list(folder.glob(\"*.csv\"))\n",
    "        print(f\"  - {folder.name}: {len(files)} arquivos CSV\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Diret√≥rio de dados brutos n√£o encontrado\")\n",
    "    print(\"üí° Execute o Notebook 1 primeiro para coletar dados\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b9a7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados da execu√ß√£o mais recente\n",
    "def load_latest_data():\n",
    "    \"\"\"Carrega os dados da execu√ß√£o mais recente\"\"\"\n",
    "    if not raw_dir.exists() or not any(raw_dir.iterdir()):\n",
    "        return None, None\n",
    "    \n",
    "    # Encontrar a pasta mais recente\n",
    "    latest_folder = max([f for f in raw_dir.iterdir() if f.is_dir()], \n",
    "                       key=lambda x: x.name)\n",
    "    \n",
    "    print(f\"üìÇ Carregando dados de: {latest_folder.name}\")\n",
    "    \n",
    "    # Carregar Twitter data\n",
    "    twitter_file = latest_folder / \"twitter_data.csv\"\n",
    "    twitter_df = None\n",
    "    if twitter_file.exists():\n",
    "        twitter_df = pd.read_csv(twitter_file)\n",
    "        twitter_df['platform'] = 'twitter'\n",
    "        print(f\"üê¶ Twitter: {len(twitter_df)} posts\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Arquivo do Twitter n√£o encontrado\")\n",
    "    \n",
    "    # Carregar Reddit data  \n",
    "    reddit_file = latest_folder / \"reddit_data.csv\"\n",
    "    reddit_df = None\n",
    "    if reddit_file.exists():\n",
    "        reddit_df = pd.read_csv(reddit_file)\n",
    "        reddit_df['platform'] = 'reddit'\n",
    "        print(f\"üî¥ Reddit: {len(reddit_df)} posts\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Arquivo do Reddit n√£o encontrado\")\n",
    "    \n",
    "    return twitter_df, reddit_df\n",
    "\n",
    "# Carregar dados\n",
    "twitter_df, reddit_df = load_latest_data()\n",
    "\n",
    "# Combinar dados se ambos existirem\n",
    "combined_df = None\n",
    "if twitter_df is not None and reddit_df is not None:\n",
    "    # Padronizar colunas para combina√ß√£o\n",
    "    twitter_columns = {'text': 'text', 'timestamp': 'timestamp', 'platform': 'platform'}\n",
    "    reddit_columns = {'title': 'text', 'timestamp': 'timestamp', 'platform': 'platform'}\n",
    "    \n",
    "    twitter_std = twitter_df[list(twitter_columns.keys())].rename(columns=twitter_columns)\n",
    "    reddit_std = reddit_df[list(reddit_columns.keys())].rename(columns=reddit_columns)\n",
    "    \n",
    "    combined_df = pd.concat([twitter_std, reddit_std], ignore_index=True)\n",
    "    print(f\"üìä Total combinado: {len(combined_df)} posts\")\n",
    "    \n",
    "elif twitter_df is not None:\n",
    "    combined_df = twitter_df.copy()\n",
    "    print(\"üìä Usando apenas dados do Twitter\")\n",
    "    \n",
    "elif reddit_df is not None:\n",
    "    combined_df = reddit_df.copy()\n",
    "    print(\"üìä Usando apenas dados do Reddit\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado encontrado para an√°lise\")\n",
    "\n",
    "if combined_df is not None:\n",
    "    # Converter timestamp para datetime\n",
    "    combined_df['timestamp'] = pd.to_datetime(combined_df['timestamp'])\n",
    "    print(f\"üìÖ Per√≠odo dos dados: {combined_df['timestamp'].min()} a {combined_df['timestamp'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830280e6",
   "metadata": {},
   "source": [
    "## üìä An√°lise Explorat√≥ria B√°sica\n",
    "\n",
    "Vamos explorar as caracter√≠sticas b√°sicas dos dados coletados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd974ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estat√≠sticas descritivas\n",
    "if combined_df is not None:\n",
    "    print(\"üìà ESTAT√çSTICAS DESCRITIVAS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Informa√ß√µes gerais\n",
    "    print(f\"üìä Total de posts: {len(combined_df)}\")\n",
    "    print(f\"üì± Plataformas: {combined_df['platform'].value_counts().to_dict()}\")\n",
    "    print(f\"üìÖ Per√≠odo: {combined_df['timestamp'].min().strftime('%Y-%m-%d %H:%M')} a {combined_df['timestamp'].max().strftime('%Y-%m-%d %H:%M')}\")\n",
    "    \n",
    "    # Estat√≠sticas de texto\n",
    "    combined_df['text_length'] = combined_df['text'].str.len()\n",
    "    print(f\"\\nüìù COMPRIMENTO DOS TEXTOS:\")\n",
    "    print(f\"  M√©dia: {combined_df['text_length'].mean():.1f} caracteres\")\n",
    "    print(f\"  Mediana: {combined_df['text_length'].median():.1f} caracteres\")\n",
    "    print(f\"  M√≠nimo: {combined_df['text_length'].min()} caracteres\")\n",
    "    print(f\"  M√°ximo: {combined_df['text_length'].max()} caracteres\")\n",
    "    \n",
    "    # Estat√≠sticas por plataforma\n",
    "    print(f\"\\nüîç POR PLATAFORMA:\")\n",
    "    for platform in combined_df['platform'].unique():\n",
    "        subset = combined_df[combined_df['platform'] == platform]\n",
    "        print(f\"  {platform.upper()}:\")\n",
    "        print(f\"    Posts: {len(subset)}\")\n",
    "        print(f\"    Texto m√©dio: {subset['text_length'].mean():.1f} chars\")\n",
    "        print(f\"    Per√≠odo: {subset['timestamp'].min().strftime('%Y-%m-%d')} a {subset['timestamp'].max().strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # Verificar dados ausentes\n",
    "    print(f\"\\nüîç DADOS AUSENTES:\")\n",
    "    missing_data = combined_df.isnull().sum()\n",
    "    for col, missing in missing_data.items():\n",
    "        if missing > 0:\n",
    "            print(f\"  {col}: {missing} ({missing/len(combined_df)*100:.1f}%)\")\n",
    "    \n",
    "    if missing_data.sum() == 0:\n",
    "        print(\"  ‚úÖ Nenhum dado ausente encontrado\")\n",
    "    \n",
    "    # Mostrar exemplos\n",
    "    print(f\"\\nüìù EXEMPLOS DE POSTS:\")\n",
    "    for platform in combined_df['platform'].unique():\n",
    "        subset = combined_df[combined_df['platform'] == platform]\n",
    "        if len(subset) > 0:\n",
    "            example = subset.iloc[0]\n",
    "            print(f\"  {platform.upper()}:\")\n",
    "            print(f\"    Texto: {example['text'][:100]}...\")\n",
    "            print(f\"    Data: {example['timestamp']}\")\n",
    "            print()\n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado dispon√≠vel para an√°lise\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
