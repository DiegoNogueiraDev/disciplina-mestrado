{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bc1bef5",
   "metadata": {},
   "source": [
    "# ğŸ“¥ Notebook 1: Coleta de Dados - X/Twitter e Reddit\n",
    "\n",
    "Este notebook demonstra o processo de coleta de dados de redes sociais (X/Twitter e Reddit) para anÃ¡lise de sentimento em tÃ³picos especÃ­ficos.\n",
    "\n",
    "## ğŸ¯ Objetivos\n",
    "- Configurar e testar coletores de dados\n",
    "- Coletar posts sobre um tÃ³pico especÃ­fico\n",
    "- Validar qualidade dos dados coletados\n",
    "- Preparar dados para prÃ©-processamento\n",
    "\n",
    "## ğŸ“‹ PrÃ©-requisitos\n",
    "- Credenciais do Reddit configuradas em `.env`\n",
    "- Ambiente Python com dependÃªncias instaladas\n",
    "- ConfiguraÃ§Ã£o do tÃ³pico em `config/topic.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c3b469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports e configuraÃ§Ã£o inicial\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Adicionar src ao path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Configurar logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Verificar estrutura do projeto\n",
    "project_root = Path(\"..\").resolve()\n",
    "print(f\"ğŸ“ DiretÃ³rio do projeto: {project_root}\")\n",
    "print(f\"ğŸ“‚ Estrutura principal:\")\n",
    "for item in [\"config\", \"src\", \"data\", \"scripts\"]:\n",
    "    path = project_root / item\n",
    "    status = \"âœ…\" if path.exists() else \"âŒ\"\n",
    "    print(f\"  {status} {item}/\")\n",
    "\n",
    "print(\"\\nğŸ”§ Python path:\")\n",
    "for p in sys.path[-3:]:\n",
    "    print(f\"  - {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82051461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar configuraÃ§Ã£o do tÃ³pico\n",
    "config_path = project_root / \"config\" / \"topic.yaml\"\n",
    "\n",
    "try:\n",
    "    with open(config_path, 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    \n",
    "    print(\"ğŸ“‹ ConfiguraÃ§Ã£o carregada:\")\n",
    "    print(f\"  ğŸ¯ TÃ³pico: {config['topic']}\")\n",
    "    print(f\"  ğŸ” Keywords: {config['keywords']}\")\n",
    "    print(f\"  ğŸ“Š Limites:\")\n",
    "    print(f\"    - Twitter: {config['limits']['twitter']}\")\n",
    "    print(f\"    - Reddit: {config['limits']['reddit']}\")\n",
    "    print(f\"  ğŸ”§ Filtros:\")\n",
    "    print(f\"    - Comprimento: {config['filters']['min_length']}-{config['filters']['max_length']}\")\n",
    "    print(f\"    - Idioma: {config['filters']['language']}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Arquivo de configuraÃ§Ã£o nÃ£o encontrado: {config_path}\")\n",
    "    print(\"ğŸ’¡ Execute: cp config/topic.yaml.example config/topic.yaml\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao carregar configuraÃ§Ã£o: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d753432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testar importaÃ§Ã£o dos scrapers\n",
    "try:\n",
    "    from scrapers.twitter import TwitterScraper\n",
    "    print(\"âœ… TwitterScraper importado com sucesso\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Erro ao importar TwitterScraper: {e}\")\n",
    "\n",
    "try:\n",
    "    from scrapers.reddit import RedditScraper  \n",
    "    print(\"âœ… RedditScraper importado com sucesso\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Erro ao importar RedditScraper: {e}\")\n",
    "\n",
    "try:\n",
    "    from utils.config import load_config, setup_logging\n",
    "    print(\"âœ… UtilitÃ¡rios importados com sucesso\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Erro ao importar utilitÃ¡rios: {e}\")\n",
    "\n",
    "# Verificar se todos os arquivos necessÃ¡rios existem\n",
    "required_files = [\n",
    "    \"src/scrapers/twitter.py\",\n",
    "    \"src/scrapers/reddit.py\", \n",
    "    \"src/utils/config.py\",\n",
    "    \".env.example\"\n",
    "]\n",
    "\n",
    "print(\"\\nğŸ“„ Verificando arquivos necessÃ¡rios:\")\n",
    "for file_path in required_files:\n",
    "    full_path = project_root / file_path\n",
    "    status = \"âœ…\" if full_path.exists() else \"âŒ\"\n",
    "    print(f\"  {status} {file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3bcc9f",
   "metadata": {},
   "source": [
    "## ğŸ¦ Teste de Coleta: X/Twitter\n",
    "\n",
    "Vamos testar a coleta de dados do X/Twitter usando `snscrape` com um limite pequeno para validaÃ§Ã£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc1227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de coleta X/Twitter com limite pequeno\n",
    "try:\n",
    "    from scrapers.twitter import TwitterScraper\n",
    "    \n",
    "    # ConfiguraÃ§Ãµes de teste\n",
    "    test_keywords = config['keywords'][:2]  # Usar apenas 2 keywords para teste\n",
    "    test_limit = 10  # Limite pequeno para teste\n",
    "    \n",
    "    print(f\"ğŸ” Testando coleta com keywords: {test_keywords}\")\n",
    "    print(f\"ğŸ“Š Limite: {test_limit} tweets\")\n",
    "    \n",
    "    # Inicializar scraper\n",
    "    twitter_scraper = TwitterScraper()\n",
    "    \n",
    "    # Realizar coleta de teste\n",
    "    tweets_data = twitter_scraper.collect(\n",
    "        keywords=test_keywords,\n",
    "        limit=test_limit,\n",
    "        lang='pt'\n",
    "    )\n",
    "    \n",
    "    if tweets_data:\n",
    "        print(f\"âœ… Coleta bem-sucedida! {len(tweets_data)} tweets coletados\")\n",
    "        \n",
    "        # Converter para DataFrame para anÃ¡lise\n",
    "        df_tweets = pd.DataFrame(tweets_data)\n",
    "        print(f\"ğŸ“Š Colunas: {list(df_tweets.columns)}\")\n",
    "        print(f\"ğŸ“ Exemplo de tweet:\")\n",
    "        if len(df_tweets) > 0:\n",
    "            print(f\"  Texto: {df_tweets.iloc[0]['text'][:100]}...\")\n",
    "            print(f\"  Data: {df_tweets.iloc[0]['timestamp']}\")\n",
    "            print(f\"  UsuÃ¡rio: {df_tweets.iloc[0].get('user_hash', 'N/A')}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Nenhum tweet coletado. Verifique as keywords ou conexÃ£o.\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro na coleta do Twitter: {e}\")\n",
    "    print(\"ğŸ’¡ Verifique se o snscrape estÃ¡ instalado: pip install snscrape\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900384ae",
   "metadata": {},
   "source": [
    "## ğŸ”´ Teste de Coleta: Reddit\n",
    "\n",
    "Vamos testar a coleta de dados do Reddit usando PRAW. **Importante**: Este teste requer credenciais configuradas no arquivo `.env`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206c632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar credenciais do Reddit\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Carregar variÃ¡veis do .env\n",
    "env_path = project_root / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path)\n",
    "    print(\"âœ… Arquivo .env encontrado\")\n",
    "else:\n",
    "    print(\"âš ï¸  Arquivo .env nÃ£o encontrado\")\n",
    "    print(\"ğŸ’¡ Execute: cp .env.example .env e configure as credenciais\")\n",
    "\n",
    "# Verificar se as credenciais estÃ£o configuradas\n",
    "required_vars = [\"REDDIT_ID\", \"REDDIT_SECRET\", \"REDDIT_AGENT\", \"REDDIT_USERNAME\", \"REDDIT_PASSWORD\"]\n",
    "missing_vars = []\n",
    "\n",
    "print(\"\\nğŸ” Verificando credenciais do Reddit:\")\n",
    "for var in required_vars:\n",
    "    value = os.getenv(var)\n",
    "    if value:\n",
    "        # Mostrar apenas primeiros caracteres para seguranÃ§a\n",
    "        display_value = value[:4] + \"...\" if len(value) > 4 else value\n",
    "        print(f\"  âœ… {var}: {display_value}\")\n",
    "    else:\n",
    "        print(f\"  âŒ {var}: nÃ£o configurado\")\n",
    "        missing_vars.append(var)\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"\\nâš ï¸  VariÃ¡veis faltando: {missing_vars}\")\n",
    "    print(\"ğŸ’¡ Configure no arquivo .env antes de continuar\")\n",
    "else:\n",
    "    print(\"\\nâœ… Todas as credenciais estÃ£o configuradas!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33ebe8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste de coleta Reddit com limite pequeno\n",
    "try:\n",
    "    from scrapers.reddit import RedditScraper\n",
    "    \n",
    "    # Verificar se as credenciais estÃ£o disponÃ­veis\n",
    "    if not missing_vars:\n",
    "        print(\"ğŸ” Testando coleta do Reddit...\")\n",
    "        \n",
    "        # ConfiguraÃ§Ãµes de teste\n",
    "        test_subreddits = config['reddit']['subreddits'][:1]  # Usar apenas 1 subreddit para teste\n",
    "        test_limit = 5  # Limite pequeno para teste\n",
    "        \n",
    "        print(f\"ğŸ“Š Subreddits: {test_subreddits}\")\n",
    "        print(f\"ğŸ“Š Limite: {test_limit} posts por subreddit\")\n",
    "        \n",
    "        # Inicializar scraper\n",
    "        reddit_scraper = RedditScraper()\n",
    "        \n",
    "        # Realizar coleta de teste\n",
    "        reddit_data = reddit_scraper.collect(\n",
    "            keywords=config['keywords'][:2],\n",
    "            subreddits=test_subreddits,\n",
    "            limit=test_limit\n",
    "        )\n",
    "        \n",
    "        if reddit_data:\n",
    "            print(f\"âœ… Coleta bem-sucedida! {len(reddit_data)} posts coletados\")\n",
    "            \n",
    "            # Converter para DataFrame para anÃ¡lise\n",
    "            df_reddit = pd.DataFrame(reddit_data)\n",
    "            print(f\"ğŸ“Š Colunas: {list(df_reddit.columns)}\")\n",
    "            print(f\"ğŸ“ Exemplo de post:\")\n",
    "            if len(df_reddit) > 0:\n",
    "                print(f\"  TÃ­tulo: {df_reddit.iloc[0]['title'][:100]}...\")\n",
    "                print(f\"  Data: {df_reddit.iloc[0]['timestamp']}\")\n",
    "                print(f\"  Subreddit: {df_reddit.iloc[0].get('subreddit', 'N/A')}\")\n",
    "                print(f\"  Score: {df_reddit.iloc[0].get('score', 'N/A')}\")\n",
    "        else:\n",
    "            print(\"âš ï¸  Nenhum post coletado. Verifique as keywords ou subreddits.\")\n",
    "            \n",
    "    else:\n",
    "        print(\"âŒ NÃ£o Ã© possÃ­vel testar Reddit sem credenciais configuradas\")\n",
    "        print(\"ğŸ’¡ Configure o arquivo .env primeiro\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro na coleta do Reddit: {e}\")\n",
    "    print(\"ğŸ’¡ Verifique se o praw estÃ¡ instalado: pip install praw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08262d68",
   "metadata": {},
   "source": [
    "## ğŸš€ Coleta Completa\n",
    "\n",
    "Uma vez que os testes funcionaram, podemos executar a coleta completa usando os limites definidos na configuraÃ§Ã£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202c0ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar coleta completa usando o script collector.py\n",
    "import subprocess\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Definir parÃ¢metros da coleta\n",
    "twitter_limit = config['limits']['twitter']\n",
    "reddit_limit = config['limits']['reddit']\n",
    "topic = config['topic']\n",
    "\n",
    "print(f\"ğŸ¯ Iniciando coleta completa para: {topic}\")\n",
    "print(f\"ğŸ“Š Limites: Twitter={twitter_limit}, Reddit={reddit_limit}\")\n",
    "\n",
    "# Criar timestamp para esta execuÃ§Ã£o\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "output_dir = project_root / \"data\" / \"raw\" / timestamp\n",
    "\n",
    "print(f\"ğŸ“ Salvando em: {output_dir}\")\n",
    "\n",
    "# Comando para executar o collector\n",
    "cmd = [\n",
    "    \"python\", \n",
    "    str(project_root / \"scripts\" / \"collector.py\"),\n",
    "    \"--config\", str(project_root / \"config\" / \"topic.yaml\"),\n",
    "    \"--limit-twitter\", str(twitter_limit),\n",
    "    \"--limit-reddit\", str(reddit_limit),\n",
    "    \"--output-dir\", str(output_dir),\n",
    "    \"--verbose\"\n",
    "]\n",
    "\n",
    "print(f\"ğŸ”§ Comando: {' '.join(cmd)}\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"ğŸš€ EXECUTANDO COLETA...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "try:\n",
    "    # Executar o comando\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, cwd=str(project_root))\n",
    "    \n",
    "    print(\"ğŸ“¤ SAÃDA:\")\n",
    "    print(result.stdout)\n",
    "    \n",
    "    if result.stderr:\n",
    "        print(\"âš ï¸  ERROS/AVISOS:\")\n",
    "        print(result.stderr)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… Coleta concluÃ­da com sucesso!\")\n",
    "        \n",
    "        # Verificar arquivos gerados\n",
    "        if output_dir.exists():\n",
    "            files = list(output_dir.glob(\"*.csv\"))\n",
    "            print(f\"ğŸ“„ Arquivos gerados: {len(files)}\")\n",
    "            for file in files:\n",
    "                size_mb = file.stat().st_size / (1024*1024)\n",
    "                print(f\"  - {file.name}: {size_mb:.2f} MB\")\n",
    "        else:\n",
    "            print(\"âš ï¸  DiretÃ³rio de saÃ­da nÃ£o encontrado\")\n",
    "    else:\n",
    "        print(f\"âŒ Coleta falhou com cÃ³digo: {result.returncode}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erro ao executar coleta: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
