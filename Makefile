# Makefile para Pipeline de AnÃ¡lise de Sentimento
# Uso: make <target>

.PHONY: help setup collect preprocess train-baseline train-advanced dashboard clean all

# ConfiguraÃ§Ãµes
PYTHON = venv/bin/python
TOPIC = "Reforma TributÃ¡ria"
TWITTER_LIMIT = 800
REDDIT_LIMIT = 200
SAMPLE_SIZE = 600

# DiretÃ³rios
DATA_RAW = data/raw
DATA_PROCESSED = data/processed
DATA_OUTPUT = data/output
MODELS_DIR = models
LOGS_DIR = logs

help:  ## Mostrar esta ajuda
	@echo "Pipeline de AnÃ¡lise de Sentimento - Comandos DisponÃ­veis:"
	@echo ""
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | sort | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}'
	@echo ""
	@echo "Exemplo de uso completo:"
	@echo "  make setup collect preprocess train-baseline dashboard"

setup:  ## Configurar ambiente (criar diretÃ³rios, instalar dependÃªncias)
	@echo "ðŸ”§ Configurando ambiente..."
	mkdir -p $(DATA_RAW) $(DATA_PROCESSED) $(DATA_OUTPUT) $(MODELS_DIR) $(LOGS_DIR)
	mkdir -p figures reports
	@if [ ! -d "venv" ]; then \
		echo "âš ï¸  Virtual environment nÃ£o encontrado. Criando..."; \
		python3 -m venv venv; \
		$(PYTHON) -m pip install --upgrade pip; \
		$(PYTHON) -m pip install -r requirements.txt; \
	fi
	@echo "âœ… Ambiente configurado!"

collect:  ## Coletar dados do Twitter e Reddit
	@echo "ðŸ“¡ Iniciando coleta de dados..."
	@echo "  Limites: Twitter=$(TWITTER_LIMIT), Reddit=$(REDDIT_LIMIT)"
	$(PYTHON) scripts/collector.py \
		--limit-twitter $(TWITTER_LIMIT) \
		--limit-reddit $(REDDIT_LIMIT) \
		--topic $(TOPIC) \
		--verbose
	@echo "âœ… Coleta concluÃ­da! Dados salvos em $(DATA_RAW)/"

collect-sample:  ## Coletar amostra pequena para testes (Twitter=10, Reddit=10)
	@echo "ðŸ“¡ Coletando amostra pequena para testes..."
	$(PYTHON) scripts/collector.py \
		--limit-twitter 10 \
		--limit-reddit 10 \
		--topic $(TOPIC) \
		--verbose

preprocess:  ## PrÃ©-processar dados coletados
	@echo "ðŸ§¹ Iniciando prÃ©-processamento..."
	$(PYTHON) scripts/preprocess.py \
		--input-dir $(DATA_RAW) \
		--output-dir $(DATA_PROCESSED) \
		--combine \
		--verbose
	@echo "âœ… PrÃ©-processamento concluÃ­do! Dados salvos em $(DATA_PROCESSED)/"

train-baseline:  ## Treinar modelo baseline (TF-IDF + Logistic Regression)
	@echo "ðŸ¤– Treinando modelo baseline..."
	@PROCESSED_FILE=$$(ls -t $(DATA_PROCESSED)/combined_processed_*.csv 2>/dev/null | head -n1); \
	if [ -z "$$PROCESSED_FILE" ]; then \
		echo "âŒ Nenhum arquivo processado encontrado. Execute 'make preprocess' primeiro."; \
		exit 1; \
	fi; \
	echo "  Usando arquivo: $$PROCESSED_FILE"; \
	$(PYTHON) scripts/train_baseline.py \
		--data-path "$$PROCESSED_FILE" \
		--sample-size $(SAMPLE_SIZE) \
		--output-dir $(MODELS_DIR) \
		--verbose
	@echo "âœ… Modelo baseline treinado! Salvo em $(MODELS_DIR)/"

train-advanced:  ## Treinar modelo avanÃ§ado (FastText + MLP)
	@echo "ðŸš€ Treinando modelo avanÃ§ado..."
	@PROCESSED_FILE=$$(ls -t $(DATA_PROCESSED)/combined_processed_*.csv 2>/dev/null | head -n1); \
	if [ -z "$$PROCESSED_FILE" ]; then \
		echo "âŒ Nenhum arquivo processado encontrado. Execute 'make preprocess' primeiro."; \
		exit 1; \
	fi; \
	echo "  Usando arquivo: $$PROCESSED_FILE"; \
	$(PYTHON) scripts/train_advanced.py \
		--data-path "$$PROCESSED_FILE" \
		--output-dir $(MODELS_DIR) \
		--epochs 30 \
		--verbose
	@echo "âœ… Modelo avanÃ§ado treinado! Salvo em $(MODELS_DIR)/"

predict:  ## Fazer prediÃ§Ãµes com modelo treinado
	@echo "ðŸ”® Fazendo prediÃ§Ãµes..."
	@PROCESSED_FILE=$$(ls -t $(DATA_PROCESSED)/combined_processed_*.csv 2>/dev/null | head -n1); \
	MODEL_FILE=$$(ls -t $(MODELS_DIR)/*.pkl $(MODELS_DIR)/*.pth 2>/dev/null | head -n1); \
	if [ -z "$$PROCESSED_FILE" ] || [ -z "$$MODEL_FILE" ]; then \
		echo "âŒ Arquivos necessÃ¡rios nÃ£o encontrados. Execute 'make preprocess' e 'make train-baseline' primeiro."; \
		exit 1; \
	fi; \
	echo "  Dados: $$PROCESSED_FILE"; \
	echo "  Modelo: $$MODEL_FILE"; \
	$(PYTHON) create_fake_predictions.py
	@echo "âœ… PrediÃ§Ãµes concluÃ­das! Resultados em $(DATA_OUTPUT)/"

dashboard:  ## Iniciar dashboard interativo
	@echo "ðŸ“Š Iniciando dashboard..."
	@if [ ! -d "$(DATA_OUTPUT)" ] || [ -z "$$(ls -A $(DATA_OUTPUT) 2>/dev/null)" ]; then \
		echo "âš ï¸  Dados de saÃ­da nÃ£o encontrados. Executando prediÃ§Ãµes..."; \
		make predict; \
	fi
	@echo "ðŸŒ Dashboard disponÃ­vel em: http://localhost:8050"
	@echo "   (Pressione Ctrl+C para parar)"
	$(PYTHON) scripts/dashboard_run.py \
		--data-path $(DATA_OUTPUT) \
		--host 0.0.0.0 \
		--port 8050

dashboard-bg:  ## Iniciar dashboard em background
	@echo "ðŸ“Š Iniciando dashboard em background..."
	nohup $(PYTHON) scripts/dashboard_run.py \
		--data-path $(DATA_OUTPUT) \
		--host 0.0.0.0 \
		--port 8050 > logs/dashboard.log 2>&1 &
	@echo "âœ… Dashboard rodando em background. Logs em logs/dashboard.log"
	@echo "ðŸŒ Acesse: http://localhost:8050"

stop-dashboard:  ## Parar dashboard em background
	@echo "ðŸ›‘ Parando dashboard..."
	pkill -f "dashboard_run.py" || echo "Dashboard nÃ£o estava rodando"

status:  ## Mostrar status do pipeline
	@echo "ðŸ“‹ Status do Pipeline:"
	@echo ""
	@echo "ðŸ“ Estrutura de diretÃ³rios:"
	@find data models logs -type f 2>/dev/null | head -20 | sed 's/^/  /'
	@echo ""
	@echo "ðŸ“Š Contagem de arquivos:"
	@echo "  Dados brutos: $$(find $(DATA_RAW) -name "*.csv" 2>/dev/null | wc -l) arquivos"
	@echo "  Dados processados: $$(find $(DATA_PROCESSED) -name "*.csv" 2>/dev/null | wc -l) arquivos"
	@echo "  Dados de saÃ­da: $$(find $(DATA_OUTPUT) -name "*.csv" 2>/dev/null | wc -l) arquivos"
	@echo "  Modelos: $$(find $(MODELS_DIR) -name "*.pkl" -o -name "*.pth" 2>/dev/null | wc -l) arquivos"
	@echo ""
	@echo "ðŸ”§ Ambiente Python:"
	@if [ -d "venv" ]; then echo "  âœ… Virtual environment ativo"; else echo "  âŒ Virtual environment nÃ£o encontrado"; fi

test:  ## Executar testes rÃ¡pidos do pipeline
	@echo "ðŸ§ª Executando testes do pipeline..."
	$(PYTHON) test_pipeline.py
	@echo "âœ… Testes concluÃ­dos!"

notebook:  ## Abrir Jupyter notebook demonstrativo
	@echo "ðŸ““ Iniciando Jupyter notebook..."
	@if [ ! -f "pipeline_demo.ipynb" ]; then \
		echo "âš ï¸  Notebook demonstrativo nÃ£o encontrado. Criando..."; \
		make create-notebook; \
	fi
	$(PYTHON) -m jupyter notebook pipeline_demo.ipynb

create-notebook:  ## Criar notebook demonstrativo
	@echo "ðŸ“ Criando notebook demonstrativo..."
	$(PYTHON) scripts/create_demo_notebook.py
	@echo "âœ… Notebook criado: pipeline_demo.ipynb"

compliance:  ## Gerar relatÃ³rio de compliance LGPD
	@echo "âš–ï¸  Gerando relatÃ³rio de compliance..."
	$(PYTHON) -c "
import sys; sys.path.append('src')
from utils.compliance import generate_compliance_report
import json

metadata = {
    'lgpd': {'legal_basis': 'Legitimate interest for academic research'},
    'tos': {'platform': 'Twitter/Reddit', 'allowed_use': 'Academic research'},
    'processing_info': {'original_records': 1000, 'final_records': 950, 'columns_removed': ['username']}
}

generate_compliance_report(metadata, 'reports/compliance_report.txt')
print('âœ… RelatÃ³rio salvo em: reports/compliance_report.txt')
"

clean:  ## Limpar arquivos temporÃ¡rios e logs
	@echo "ðŸ§¹ Limpando arquivos temporÃ¡rios..."
	find . -name "*.pyc" -delete
	find . -name "__pycache__" -type d -exec rm -rf {} +
	find . -name ".pytest_cache" -type d -exec rm -rf {} +
	rm -f logs/*.log
	@echo "âœ… Limpeza concluÃ­da!"

clean-data:  ## Limpar todos os dados (CUIDADO!)
	@echo "âš ï¸  ATENÃ‡ÃƒO: Isso irÃ¡ apagar todos os dados coletados!"
	@read -p "Tem certeza? (y/N): " confirm && [ "$$confirm" = "y" ]
	rm -rf $(DATA_RAW)/* $(DATA_PROCESSED)/* $(DATA_OUTPUT)/*
	@echo "ðŸ—‘ï¸  Dados apagados!"

all: setup collect preprocess train-baseline predict dashboard  ## Executar pipeline completo

demo: setup collect-sample preprocess train-baseline predict dashboard  ## Demo rÃ¡pido com amostra pequena

# Targets de desenvolvimento
dev-install:  ## Instalar dependÃªncias de desenvolvimento
	$(PYTHON) -m pip install jupyter matplotlib seaborn pytest black isort

format:  ## Formatar cÃ³digo Python
	$(PYTHON) -m black src/ scripts/
	$(PYTHON) -m isort src/ scripts/

lint:  ## Verificar qualidade do cÃ³digo
	$(PYTHON) -m black --check src/ scripts/
	$(PYTHON) -m isort --check-only src/ scripts/

# InformaÃ§Ãµes do sistema
info:  ## Mostrar informaÃ§Ãµes do sistema
	@echo "ðŸ” InformaÃ§Ãµes do Sistema:"
	@echo "  Python: $$($(PYTHON) --version 2>&1)"
	@echo "  PyTorch: $$($(PYTHON) -c 'import torch; print(torch.__version__)' 2>/dev/null || echo 'NÃ£o instalado')"
	@echo "  CUDA disponÃ­vel: $$($(PYTHON) -c 'import torch; print(torch.cuda.is_available())' 2>/dev/null || echo 'N/A')"
	@echo "  GPU: $$($(PYTHON) -c 'import torch; print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Nenhuma\")' 2>/dev/null || echo 'N/A')"
	@echo "  EspaÃ§o em disco: $$(df -h . | tail -n1 | awk '{print $$4}') disponÃ­vel"

# Backup
backup:  ## Criar backup dos dados e modelos
	@echo "ðŸ’¾ Criando backup..."
	@BACKUP_NAME="backup_$$(date +%Y%m%d_%H%M%S)"; \
	mkdir -p backups; \
	tar -czf "backups/$$BACKUP_NAME.tar.gz" data/ models/ config/ || true; \
	echo "âœ… Backup criado: backups/$$BACKUP_NAME.tar.gz"

# Help adicional
usage:  ## Mostrar exemplos de uso
	@echo "ðŸ“– Exemplos de Uso:"
	@echo ""
	@echo "1. Pipeline completo (primeira vez):"
	@echo "   make setup collect preprocess train-baseline dashboard"
	@echo ""
	@echo "2. DemonstraÃ§Ã£o rÃ¡pida:"
	@echo "   make demo"
	@echo ""
	@echo "3. Apenas coleta de novos dados:"
	@echo "   make collect preprocess predict"
	@echo ""
	@echo "4. Retreinar modelo:"
	@echo "   make train-baseline"
	@echo ""
	@echo "5. Ver status do sistema:"
	@echo "   make status"